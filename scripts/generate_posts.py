"""
generate_posts.py â€” AI æ–°æ–‡ç« ç”Ÿæˆå™¨ (Python ç‰ˆï¼Œå¤šæ¨¡å‹æ”¯æ´)

é€é AI API ç”Ÿæˆç¬¦åˆ GEO é»ƒé‡‘éª¨æ¶çµæ§‹çš„éƒ¨è½æ ¼æ–‡ç« ï¼Œ
å†é€é WordPress REST API + æ‡‰ç”¨ç¨‹å¼å¯†ç¢¼ç›´æ¥ç™¼å¸ƒï¼Œä¸éœ€å®‰è£ä»»ä½• WordPress æ’ä»¶ã€‚

æ”¯æ´æ¨¡å‹:
  - DeepSeek V3.2 / R1 (via GMI Cloud)
  - GPT-5.2 (via GMI Cloud)
  - GPT-4o / 4o-mini (via OpenAI)
  - Kimi K2.5 (via Moonshot AI)
  - Gemini 3 Pro (via Google)

ä½¿ç”¨æ–¹å¼ï¼š
    python scripts/generate_posts.py                              # é è¨­: gpt-4o, 1 ç¯‡è‰ç¨¿
    python scripts/generate_posts.py --model deepseek-chat        # DeepSeek V3.2 (GMI)
    python scripts/generate_posts.py --model gpt-5.2              # GPT-5.2 (GMI)
    python scripts/generate_posts.py --model kimi-k2.5            # Kimi K2.5 (Moonshot)
    python scripts/generate_posts.py --model gemini-3-pro         # Gemini 3 Pro (Google)
    python scripts/generate_posts.py --count 3 --status draft     # 3 ç¯‡è‰ç¨¿
    python scripts/generate_posts.py --dry-run                    # åªç”Ÿæˆä¸ç™¼å¸ƒ
    python scripts/generate_posts.py --list-models                # åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹
"""

import os
import sys
import json
import logging
import argparse
from datetime import datetime

# å°‡å°ˆæ¡ˆæ ¹ç›®éŒ„èˆ‡ core/ åŠ å…¥ sys.path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "core"))

from core.wp_bridge import WordPressBridge
from retry_utils import retry_with_backoff
from dotenv import load_dotenv

# â”€â”€â”€ æ—¥èªŒè¨­å®š â”€â”€â”€
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
if not logger.handlers:
    handler = logging.StreamHandler()
    handler.setFormatter(
        logging.Formatter('%(asctime)s [%(levelname)s] %(message)s', datefmt='%H:%M:%S')
    )
    logger.addHandler(handler)

# â”€â”€â”€ å¸¸é‡ â”€â”€â”€
LANGUAGE_MAP = {
    "zh-TW": "ç¹é«”ä¸­æ–‡",
    "zh-CN": "ç®€ä½“ä¸­æ–‡",
    "en": "English",
}

# â”€â”€â”€ å¤šæ¨¡å‹è¨»å†Šè¡¨ â”€â”€â”€
# æ‰€æœ‰æ¨¡å‹éƒ½é€é OpenAI ç›¸å®¹ API å‘¼å«ï¼Œåªéœ€åˆ‡æ› base_url å’Œ API key
MODEL_REGISTRY = {
    # â”€â”€ GMI Cloud (DeepSeek + GPT-5.2) â”€â”€
    "deepseek-chat": {
        "base_url": "https://api.gmi-serving.com/v1",
        "api_key_env": "GMI_API_KEY",
        "model": "deepseek-ai/DeepSeek-V3.2",
        "label": "DeepSeek V3.2 Chat (GMI Cloud)",
    },
    "deepseek-reasoner": {
        "base_url": "https://api.gmi-serving.com/v1",
        "api_key_env": "GMI_API_KEY",
        "model": "deepseek-ai/DeepSeek-R1",
        "label": "DeepSeek R1 Reasoner (GMI Cloud)",
    },
    "gpt-5.2": {
        "base_url": "https://api.gmi-serving.com/v1",
        "api_key_env": "GMI_API_KEY",
        "model": "gpt-5.2",
        "label": "GPT-5.2 (GMI Cloud)",
    },
    # â”€â”€ OpenAI ç›´é€£ â”€â”€
    "gpt-4o": {
        "base_url": None,  # ä½¿ç”¨é è¨­ OpenAI endpoint
        "api_key_env": "OPENAI_API_KEY",
        "model": "gpt-4o",
        "label": "GPT-4o (OpenAI)",
    },
    "gpt-4o-mini": {
        "base_url": None,
        "api_key_env": "OPENAI_API_KEY",
        "model": "gpt-4o-mini",
        "label": "GPT-4o Mini (OpenAI)",
    },
    # â”€â”€ Kimi K2.5 (Moonshot AI) â”€â”€
    "kimi-k2.5": {
        "base_url": "https://api.moonshot.ai/v1",
        "api_key_env": "MOONSHOT_API_KEY",
        "model": "kimi-k2.5",
        "label": "Kimi K2.5 (Moonshot)",
    },
    # â”€â”€ Gemini 3 Pro (Google) â”€â”€
    "gemini-3-pro": {
        "base_url": "https://generativelanguage.googleapis.com/v1beta/openai/",
        "api_key_env": "GEMINI_API_KEY",
        "model": "gemini-3-pro-preview",
        "label": "Gemini 3 Pro Preview (Google)",
    },
}


def get_ai_client(model_name):
    """æ ¹æ“šæ¨¡å‹åç¨±å»ºç«‹å°æ‡‰çš„ OpenAI ç›¸å®¹ clientã€‚

    :param model_name: MODEL_REGISTRY ä¸­çš„ key
    :return: (client, model_string, label) æˆ–æ‹‹å‡º ValueError/EnvironmentError
    """
    try:
        import openai
    except ImportError:
        raise ImportError("è«‹å…ˆå®‰è£ openai: pip install openai")

    if model_name not in MODEL_REGISTRY:
        raise ValueError(
            f"æœªçŸ¥çš„æ¨¡å‹: {model_name}\n"
            f"å¯ç”¨æ¨¡å‹: {', '.join(MODEL_REGISTRY.keys())}"
        )

    config = MODEL_REGISTRY[model_name]
    api_key = os.getenv(config["api_key_env"])

    if not api_key:
        raise EnvironmentError(
            f"âŒ ç¼ºå°‘ API Key: è«‹åœ¨ .env ä¸­è¨­å®š {config['api_key_env']}"
        )

    client_kwargs = {"api_key": api_key}
    if config["base_url"]:
        client_kwargs["base_url"] = config["base_url"]

    client = openai.OpenAI(**client_kwargs)
    return client, config["model"], config["label"]


def list_models():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹åŠå…¶è¨­å®šç‹€æ…‹ã€‚"""
    print("\nğŸ“‹ å¯ç”¨ AI æ¨¡å‹:")
    print("-" * 65)
    print(f"  {'æ¨¡å‹åç¨±':<20} {'èªªæ˜':<30} {'API Key ç‹€æ…‹'}")
    print("-" * 65)
    for name, config in MODEL_REGISTRY.items():
        api_key = os.getenv(config["api_key_env"], "")
        status = "âœ… å·²è¨­å®š" if api_key else "âŒ æœªè¨­å®š"
        print(f"  {name:<20} {config['label']:<30} {status} ({config['api_key_env']})")
    print("-" * 65)
    print()


SYSTEM_MESSAGE = (
    "You are a professional SEO/AEO/GEO content writer. "
    "You produce well-structured HTML blog articles optimized for both "
    "traditional search engines and AI answer engines (Perplexity, Gemini, ChatGPT). "
    "Every paragraph must be semantically self-contained so AI can independently cite it."
)

GEO_PROMPT_TEMPLATE = """è«‹æ ¹æ“šä»¥ä¸‹é¡Œç›®æ’°å¯«ä¸€ç¯‡å®Œæ•´çš„ã€é«˜å“è³ªçš„éƒ¨è½æ ¼æ–‡ç« ã€‚

**é¡Œç›®:** {topic}

**èªè¨€:** {language_name}

**æ–‡ç« çµæ§‹è¦æ±‚ (åš´æ ¼éµå¾ª GEO Golden Skeleton):**

1. **å°è¨€** (åƒ… 1 æ®µ, 5-7 è¡Œ)
   - ç¬¬ä¸€å¥å¿…é ˆæ˜¯å¯è¢« AI ç›´æ¥å¼•ç”¨çš„ã€Œæ‘˜è¦ç­”æ¡ˆã€(citeable first sentence)
   - å¿…å« 5 å…ƒç´ : ä¸»é¡Œ â†’ é—œéµå„ªå‹¢ â†’ è®€è€…ç—›é» â†’ æœ¬æ–‡æ‰¿è«¾ â†’ å°ˆå®¶è¦–è§’

2. **H2-1: æ ¸å¿ƒæ¦‚å¿µ** (åŸå›  â†’ çµæœ)
   - ç¬¬ä¸€è¡Œç›´æ¥å›ç­”ã€Œç‚ºä»€éº¼é€™å¾ˆé‡è¦ï¼Ÿã€(å› æœå¥å‹)
   - H3: ç¨ç‰¹ä¹‹è™• (3 é»äº‹å¯¦å¥)
   - H3: å¦‚ä½•å¸¶ä¾†å¥½è™• (3 é»: æ¢ä»¶â†’ä½¿ç”¨è€…å¥½è™•)
   - H3: å‹å–„åšæ³•å¦‚ä½•å®ˆè­·æ­¤åƒ¹å€¼ (å¯¦éš›åšæ³• + åƒ¹å€¼ç¸½çµå¥)

3. **H2-2: å¯¦éš›æ‡‰ç”¨** (æ¢ä»¶ â†’ çµæœ)
   - ç¬¬ä¸€è¡Œå¯è¢« AI ç›´æ¥ç”Ÿæˆç‚ºã€ŒçŸ¥è­˜å›ç­”ã€
   - H3: æ‡‰ç”¨æ¢ä»¶ (å¼•è¨€ + 3 é»å…·é«”æ¢ä»¶)
   - H3: å¯¦éš›åšæ³•çš„çµåˆ (å¼•è¨€ + 3 é»)
   - æ®µæœ«æ”¶æŸ

4. **H2-3: åŸ·è¡Œæ­¥é©Ÿ** (æ–¹æ³• â†’ çµæœ)
   - H3-1/2/3: æ–¹æ³•é¡åˆ¥ (æ¯é¡ 2 å­é … + 1 å¥åƒ¹å€¼ç¸½çµ)
   - **å¿…é ˆåŒ…å«æ¯”è¼ƒè¡¨æ ¼**: | é¡åˆ¥ | æ¢ä»¶ | åšæ³• | å„ªé» |

5. **H2-4: æ³¨æ„äº‹é …èˆ‡é¢¨éšª** (ç®¡ç† â†’ å®‰å¿ƒ)
   - H3: è‡ªç„¶/éä¾µå…¥å¼ç®¡ç† (5 é»å…·é«”æ–¹æ³•)
   - H3: å“è³ªæ§ç®¡èˆ‡èªè­‰ (ç¬¬ä¸‰æ–¹è§’è‰²)

6. **çµè«–** (åƒ… 1 æ®µ)
   - å£“ç¸®å‰ 4 å€‹ H2 æ ¸å¿ƒåƒ¹å€¼ + é‚€è«‹è¡Œå‹•

7. **FAQ** (å›ºå®š 3 é¡Œ)
   - å•å¥ â†’ ç›´æ¥ç­”æ¡ˆ (æ¯é¡Œä¸è¶…é 4 è¡Œ)
   - åŒ…å« FAQPage JSON-LD Schema

8. **åƒ¹å€¼ç¢ºèª** (GEO å„ªåŒ–)
   - æ€éº¼é¸/æ€éº¼åˆ¤æ–· (3 é» Checklist)
   - ä¸‹ä¸€æ­¥è¡Œå‹• (3 å€‹å¯åŸ·è¡Œè¡Œå‹•)

**å¯«ä½œè¦å‰‡:**
- æ¯å€‹æ®µè½èªç¾©è‡ªè¶³ (self-contained)ï¼Œå¯è¢« AI ç¨ç«‹å¼•ç”¨ï¼Œä¸ä½¿ç”¨ã€Œå¦‚å‰æ‰€è¿°ã€ç­‰å›æº¯èªå¥
- æ¯å€‹ H2/H3 å€æ®µçš„ç¬¬ä¸€å¥è©±å¿…é ˆæ˜¯å¯è¢« AI ç›´æ¥æå–çš„ã€Œæ‘˜è¦ç­”æ¡ˆã€
- ä¸å¯å‡ºç¾ã€Œæœ¬æ–‡å°‡ä»‹ç´¹ã€ç­‰ç©ºæ³›èªå¥
- ä¸å¯ä¸€æ¬¡æ®µè½è«‡å¤šå€‹é‡é»
- ä½¿ç”¨å…·é«”æ•¸æ“šå’Œæ¡ˆä¾‹ï¼Œé¿å…ã€Œé«˜å“è³ªã€ã€Œå¾ˆé‡è¦ã€ç­‰ç©ºæ³›å½¢å®¹
- æ¤å…¥å…·é«”å°ˆå®¶èº«åˆ†è§€é»
- å¼•ç”¨ç¬¬ä¸‰æ–¹å¯¦é«” (ç¤¾ç¾¤ã€é–‹ç™¼è€…æ–‡ä»¶ç­‰) å¢å¼·å¯ä¿¡åº¦
- å…§å®¹é•·åº¦è‡³å°‘ 2000 å­—
- ç›´æ¥è¼¸å‡ºå®Œæ•´ HTML å…§å®¹ (ä½¿ç”¨ h2, h3, p, ul, ol, li, table, strong, em ç­‰æ¨™ç±¤)
- ä¸è¦æœ‰ Markdown æ¨™è¨˜æˆ–èªªæ˜æ–‡å­—
- ä¸è¦åŒ…å« h1 æ¨™ç±¤ (WordPress æœƒè‡ªå‹•è™•ç†æ¨™é¡Œ)
- ä¸è¦åŒ…å« ```html ç­‰ç¨‹å¼ç¢¼æ¡†æ¶æ¨™è¨˜
- FAQ çš„ JSON-LD Schema ç”¨ <script type="application/ld+json"> æ¨™ç±¤åŒ…è£¹

**è«‹ç›´æ¥è¼¸å‡ºå®Œæ•´çš„ HTML æ–‡ç« å…§å®¹:**"""


# â”€â”€â”€ é¡Œç›®ç®¡ç† â”€â”€â”€

def load_topics(topics_file):
    """å¾ Markdown é¡Œç›®æª”æ¡ˆè®€å–é¡Œç›®æ¸…å–®ã€‚

    æ”¯æ´å…©ç¨®æ ¼å¼ï¼š
    - ç·¨è™Ÿæ ¼å¼: '1. é¡Œç›®åç¨±'
    - ç´”æ–‡å­—æ ¼å¼: æ¯è¡Œä¸€å€‹é¡Œç›®
    """
    if not os.path.exists(topics_file):
        logger.error(f"é¡Œç›®æª”æ¡ˆä¸å­˜åœ¨: {topics_file}")
        return []

    with open(topics_file, "r", encoding="utf-8") as f:
        lines = f.readlines()

    topics = []
    for line in lines:
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        # å˜—è©¦è§£æ '1. é¡Œç›®' æ ¼å¼
        if "." in line and line.split(".")[0].strip().isdigit():
            title = line.split(".", 1)[1].strip()
        else:
            title = line
        if title:
            topics.append(title)

    logger.info(f"ğŸ“‹ è¼‰å…¥ {len(topics)} å€‹é¡Œç›® ({topics_file})")
    return topics


def load_used_topics(tracking_file):
    """è®€å–å·²ä½¿ç”¨é¡Œç›®è¿½è¹¤æª”ã€‚"""
    if not os.path.exists(tracking_file):
        return set()
    try:
        with open(tracking_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        return set(data.get("used", []))
    except (json.JSONDecodeError, KeyError):
        logger.warning(f"è¿½è¹¤æª”æ¡ˆæå£ï¼Œé‡æ–°é–‹å§‹: {tracking_file}")
        return set()


def save_used_topics(tracking_file, used_set):
    """å°‡å·²ä½¿ç”¨é¡Œç›®å¯«å›è¿½è¹¤æª”ã€‚"""
    data = {
        "updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "count": len(used_set),
        "used": sorted(list(used_set)),
    }
    os.makedirs(os.path.dirname(tracking_file), exist_ok=True)
    with open(tracking_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    logger.info(f"ğŸ’¾ å·²æ›´æ–°é¡Œç›®è¿½è¹¤ ({len(used_set)} å€‹å·²ä½¿ç”¨)")


def select_topics(all_topics, used_topics, count):
    """æŒ‘é¸æœªä½¿ç”¨çš„é¡Œç›®ï¼Œå…¨éƒ¨ç”¨å®Œå¾Œè‡ªå‹•é‡ç½®ã€‚"""
    available = [t for t in all_topics if t not in used_topics]
    if not available:
        logger.info("ğŸ”„ æ‰€æœ‰é¡Œç›®å·²ä½¿ç”¨å®Œç•¢ï¼Œé‡ç½®é¡Œç›®æ± ")
        used_topics.clear()
        available = list(all_topics)

    selected = available[:count]
    logger.info(f"âœ… é¸å– {len(selected)} å€‹é¡Œç›® (å‰©é¤˜ {len(available) - len(selected)} å€‹)")
    return selected


# â”€â”€â”€ AI ç”Ÿæˆ â”€â”€â”€

def build_geo_prompt(topic, language="zh-TW"):
    """æ§‹å»º GEO é»ƒé‡‘éª¨æ¶ Promptã€‚"""
    language_name = LANGUAGE_MAP.get(language, "ç¹é«”ä¸­æ–‡")
    return GEO_PROMPT_TEMPLATE.format(topic=topic, language_name=language_name)


def strip_code_fences(content):
    """ç§»é™¤ GPT æœ‰æ™‚é™„åŠ çš„ Markdown ç¨‹å¼ç¢¼æ¡†æ¶ã€‚"""
    content = content.strip()
    if content.startswith("```html"):
        content = content[7:]
    elif content.startswith("```"):
        content = content[3:]
    if content.endswith("```"):
        content = content[:-3]
    return content.strip()


def generate_article(topic, model="gpt-4o", language="zh-TW"):
    """å‘¼å« AI API ç”Ÿæˆå®Œæ•´ HTML æ–‡ç«  (æ”¯æ´å¤šæ¨¡å‹)ã€‚

    :param topic: æ–‡ç« é¡Œç›®
    :param model: MODEL_REGISTRY ä¸­çš„æ¨¡å‹åç¨±
    :param language: æ–‡ç« èªè¨€
    :return: dict {title, content, model, tokens} æˆ– None
    """
    try:
        import openai
    except ImportError:
        logger.error("è«‹å…ˆå®‰è£ openai: pip install openai")
        return None

    # é€éæ¨¡å‹è¨»å†Šè¡¨å–å¾—å°æ‡‰çš„ client
    try:
        client, model_string, label = get_ai_client(model)
    except (ValueError, EnvironmentError, ImportError) as e:
        logger.error(str(e))
        return None

    logger.info(f"  ğŸ”— ä½¿ç”¨æ¨¡å‹: {label} ({model_string})")

    prompt = build_geo_prompt(topic, language)

    def _call_ai():
        return client.chat.completions.create(
            model=model_string,
            messages=[
                {"role": "system", "content": SYSTEM_MESSAGE},
                {"role": "user", "content": prompt},
            ],
            temperature=0.7,
            max_tokens=4096,
        )

    try:
        response = retry_with_backoff(
            _call_ai,
            max_retries=3,
            base_delay=2.0,
            max_delay=30.0,
            retryable_exceptions=(
                openai.APIError,
                openai.APIConnectionError,
                openai.RateLimitError,
            ),
        )

        content = response.choices[0].message.content
        tokens = response.usage.total_tokens if response.usage else 0

        # æ¸…ç†å¯èƒ½çš„ Markdown åŒ…è£
        content = strip_code_fences(content)

        # é©—è­‰å…§å®¹å“è³ª
        text_length = len(content.replace("<", " ").replace(">", " "))
        if text_length < 500:
            logger.warning(f"âš ï¸ ç”Ÿæˆå…§å®¹éçŸ­ ({text_length} å­—)ï¼Œå¯èƒ½å“è³ªä¸ä½³")

        logger.info(f"ğŸ¤– æ–‡ç« ç”Ÿæˆå®Œæˆ: '{topic}' ({tokens} tokens, {len(content)} chars)")
        return {
            "title": topic,
            "content": content,
            "model": model_string,
            "tokens": tokens,
        }

    except Exception as e:
        logger.error(f"âŒ AI API å‘¼å«å¤±æ•— (å·²é‡è©¦ 3 æ¬¡): {e}")
        return None


# â”€â”€â”€ WordPress ç™¼å¸ƒ â”€â”€â”€

def publish_article(article, status="draft", category=None):
    """é€é WordPress REST API ç™¼å¸ƒæ–‡ç« ã€‚

    :return: WordPress API å›æ‡‰ dict æˆ– None
    """
    wp_site = os.getenv("WP_SITE")
    wp_user = os.getenv("WP_USER")
    wp_pwd = os.getenv("WP_PWD")

    if not all([wp_site, wp_user, wp_pwd]):
        logger.error("âŒ WordPress èªè­‰è³‡è¨Šæœªè¨­å®š (WP_SITE, WP_USER, WP_PWD)")
        return None

    bridge = WordPressBridge(wp_site, wp_user, wp_pwd)
    cat_list = [category] if category else None

    result = bridge.post_article(
        title=article["title"],
        content=article["content"],
        status=status,
        categories=cat_list,
    )

    return result


# â”€â”€â”€ ä¸»ç¨‹å¼ â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(
        description="AI æ–°æ–‡ç« ç”Ÿæˆå™¨ â€” æ”¯æ´å¤šæ¨¡å‹ (DeepSeek/GPT/Kimi/Gemini) + WordPress REST API"
    )
    parser.add_argument(
        "--count", type=int, default=1,
        help="è¦ç”Ÿæˆçš„æ–‡ç« æ•¸é‡ (é è¨­: 1)"
    )
    parser.add_argument(
        "--status", choices=["draft", "pending", "publish"], default="draft",
        help="WordPress æ–‡ç« ç‹€æ…‹ (é è¨­: draft)"
    )
    parser.add_argument(
        "--category", type=int, default=None,
        help="WordPress åˆ†é¡ ID"
    )
    parser.add_argument(
        "--topics-file", default=None,
        help="è‡ªè¨‚é¡Œç›®æª”æ¡ˆè·¯å¾‘ (é è¨­: data/topics_50.md)"
    )
    parser.add_argument(
        "--model", default="gpt-4o",
        help="AI æ¨¡å‹åç¨± (é è¨­: gpt-4o)ã€‚å¯ç”¨: " + ", ".join(MODEL_REGISTRY.keys())
    )
    parser.add_argument(
        "--language", default="zh-TW", choices=["zh-TW", "zh-CN", "en"],
        help="æ–‡ç« èªè¨€ (é è¨­: zh-TW)"
    )
    parser.add_argument(
        "--dry-run", action="store_true",
        help="åªç”Ÿæˆä¸ç™¼å¸ƒï¼Œé è¦½çµæœ"
    )
    parser.add_argument(
        "--list-models", action="store_true",
        help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ AI æ¨¡å‹"
    )
    args = parser.parse_args()

    # è¼‰å…¥ç’°å¢ƒè®Šæ•¸
    load_dotenv()

    # åˆ—å‡ºæ¨¡å‹æ¨¡å¼
    if args.list_models:
        list_models()
        return

    # è§£ææª”æ¡ˆè·¯å¾‘
    project_root = os.path.join(os.path.dirname(__file__), "..")
    topics_file = args.topics_file or os.path.join(project_root, "data", "topics_50.md")
    tracking_file = os.path.join(project_root, "data", "used_topics.json")

    logger.info("=" * 60)
    logger.info("ğŸš€ AI æ–°æ–‡ç« ç”Ÿæˆå™¨ å•Ÿå‹•")
    logger.info(f"   æ¨¡å‹: {args.model} | æ•¸é‡: {args.count} | ç‹€æ…‹: {args.status}")
    logger.info(f"   èªè¨€: {args.language} | Dry-run: {args.dry_run}")
    logger.info("=" * 60)

    # 1. è¼‰å…¥é¡Œç›®
    all_topics = load_topics(topics_file)
    if not all_topics:
        logger.error(f"âŒ ç„¡æ³•è¼‰å…¥é¡Œç›®ï¼Œè«‹æª¢æŸ¥: {topics_file}")
        return

    # 2. æŒ‘é¸æœªä½¿ç”¨çš„é¡Œç›®
    used_topics = load_used_topics(tracking_file)
    selected = select_topics(all_topics, used_topics, args.count)

    if not selected:
        logger.error("âŒ æ²’æœ‰å¯ç”¨çš„é¡Œç›®")
        return

    # 3. é€ä¸€ç”Ÿæˆ + ç™¼å¸ƒ
    results = {
        "generated": 0,
        "published": 0,
        "failed": 0,
        "details": [],
    }

    for i, topic in enumerate(selected, 1):
        logger.info(f"\n[{i}/{len(selected)}] æ­£åœ¨ç”Ÿæˆ: {topic}")
        logger.info("-" * 40)

        # ç”Ÿæˆæ–‡ç« 
        article = generate_article(topic, model=args.model, language=args.language)
        if not article:
            logger.error(f"  âŒ æ–‡ç« ç”Ÿæˆå¤±æ•—: {topic}")
            results["failed"] += 1
            continue

        results["generated"] += 1
        used_topics.add(topic)

        # Dry-run æ¨¡å¼: åªé è¦½
        if args.dry_run:
            logger.info(f"  [DRY RUN] é è¦½: {article['title']}")
            logger.info(f"  å…§å®¹é•·åº¦: {len(article['content'])} chars, Token: {article['tokens']}")
            print(f"\n{'='*60}")
            print(f"æ¨™é¡Œ: {article['title']}")
            print(f"{'='*60}")
            print(article["content"][:800])
            print("...\n")
            results["details"].append({
                "topic": topic,
                "tokens": article["tokens"],
                "status": "dry-run",
            })
            continue

        # ç™¼å¸ƒåˆ° WordPress
        wp_result = publish_article(article, status=args.status, category=args.category)
        if wp_result:
            post_id = wp_result.get("id", "unknown")
            post_url = wp_result.get("link", "")
            logger.info(f"  âœ… ç™¼å¸ƒæˆåŠŸ! ID: {post_id}")
            logger.info(f"     URL: {post_url}")
            results["published"] += 1
            results["details"].append({
                "topic": topic,
                "post_id": post_id,
                "url": post_url,
                "tokens": article["tokens"],
                "status": "published",
            })
        else:
            logger.error(f"  âŒ ç™¼å¸ƒå¤±æ•—: {topic}")
            results["failed"] += 1
            results["details"].append({
                "topic": topic,
                "tokens": article["tokens"],
                "status": "publish_failed",
            })

    # 4. å„²å­˜é¡Œç›®è¿½è¹¤
    save_used_topics(tracking_file, used_topics)

    # 5. è¼¸å‡ºæ‘˜è¦
    print(f"\n{'='*60}")
    print("ğŸ“Š åŸ·è¡Œæ‘˜è¦")
    print(f"{'='*60}")
    print(f"  ç”Ÿæˆ: {results['generated']} ç¯‡")
    print(f"  ç™¼å¸ƒ: {results['published']} ç¯‡")
    print(f"  å¤±æ•—: {results['failed']} ç¯‡")

    if results["details"]:
        print(f"\nğŸ“ è©³ç´°çµæœ:")
        for d in results["details"]:
            status_icon = {"published": "âœ…", "dry-run": "ğŸ‘ï¸", "publish_failed": "âŒ"}.get(
                d["status"], "â“"
            )
            line = f"  {status_icon} {d['topic']} ({d['tokens']} tokens)"
            if d.get("url"):
                line += f"\n     â†’ {d['url']}"
            print(line)

    print()


if __name__ == "__main__":
    main()
